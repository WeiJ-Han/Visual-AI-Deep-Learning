{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b54fbbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T02:49:10.219317Z",
     "start_time": "2022-07-01T02:49:10.143066Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten \n",
    "#Conv2D卷積層、MaxPooling2D最大池化層、Flatten將卷積層或池化層轉換為1軸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e0d016",
   "metadata": {},
   "source": [
    "# LeNet-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91154bee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T02:49:13.128715Z",
     "start_time": "2022-07-01T02:49:11.592707Z"
    }
   },
   "outputs": [],
   "source": [
    "#載入資料集並做資料預處理\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 28 ,28 ,1).astype('float32')\n",
    "x_test = x_test.reshape(10000, 28 , 28 ,1).astype('float32')\n",
    "#Cov2D必須轉換為4軸陣列[樣本數 x 寬 x 高 x 顏色通道]，顏色通道單色1彩色3\n",
    "#astype 轉為浮點數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76d9793f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T02:49:13.581306Z",
     "start_time": "2022-07-01T02:49:13.305443Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train /=255\n",
    "x_test /= 255\n",
    "\n",
    "n_classes =10\n",
    "y_train = to_categorical(y_train, n_classes)\n",
    "y_test = to_categorical(y_test, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6e80ecb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T02:49:17.955402Z",
     "start_time": "2022-07-01T02:49:16.046353Z"
    }
   },
   "outputs": [],
   "source": [
    "#規劃CNN模型架構\n",
    "model = Sequential()\n",
    "# 第1卷積層:\n",
    "model.add(Conv2D(32, kernel_size=(3,3), activation='relu',\n",
    "                    input_shape=(28, 28, 1)))#32個濾鏡，3x3濾鏡尺寸,\n",
    "# 第2卷積層，並搭配最大池化層與丟棄層:\n",
    "model.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2))) #減少特徵圖尺寸\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "\n",
    "#搭配丟棄法的密集隱藏層\n",
    "model.add(Dense(128, activation= 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "#輸出層\n",
    "model.add (Dense(n_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08625024",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T02:49:20.058702Z",
     "start_time": "2022-07-01T02:49:19.879996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 12, 12, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               1179776   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#顯示模型摘要\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fabfed98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-30T14:43:25.044006Z",
     "start_time": "2022-06-30T14:07:23.243181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 218s 459ms/step - loss: 0.2427 - accuracy: 0.9263 - val_loss: 0.0556 - val_accuracy: 0.9816\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 216s 461ms/step - loss: 0.0846 - accuracy: 0.9747 - val_loss: 0.0409 - val_accuracy: 0.9872\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 215s 458ms/step - loss: 0.0648 - accuracy: 0.9808 - val_loss: 0.0346 - val_accuracy: 0.9891\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 215s 459ms/step - loss: 0.0531 - accuracy: 0.9841 - val_loss: 0.0314 - val_accuracy: 0.9897\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 215s 459ms/step - loss: 0.0446 - accuracy: 0.9861 - val_loss: 0.0313 - val_accuracy: 0.9900\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 216s 461ms/step - loss: 0.0388 - accuracy: 0.9877 - val_loss: 0.0301 - val_accuracy: 0.9907\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 216s 461ms/step - loss: 0.0342 - accuracy: 0.9892 - val_loss: 0.0293 - val_accuracy: 0.9907\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 216s 460ms/step - loss: 0.0321 - accuracy: 0.9895 - val_loss: 0.0278 - val_accuracy: 0.9920\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 216s 460ms/step - loss: 0.0299 - accuracy: 0.9905 - val_loss: 0.0254 - val_accuracy: 0.9922\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 216s 461ms/step - loss: 0.0281 - accuracy: 0.9907 - val_loss: 0.0260 - val_accuracy: 0.9925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ee12b277f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#編譯訓練模型\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,batch_size=128, epochs=10 , verbose=1,\n",
    "               validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8644b375",
   "metadata": {},
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cff43a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T02:50:41.018947Z",
     "start_time": "2022-07-01T02:50:21.021472Z"
    }
   },
   "outputs": [],
   "source": [
    "#載入資料集並進行資料預處理\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import tflearn.datasets.oxflower17 as oxflower17\n",
    "X, Y = oxflower17.load_data(one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f971058d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T02:51:29.914624Z",
     "start_time": "2022-07-01T02:50:45.848502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:514: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 第一卷積塊:\n",
    "model.add(Conv2D(96, kernel_size=(11, 11), strides=(4, 4), activation='relu',\n",
    "                 input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 第二卷積塊:\n",
    "model.add(Conv2D(256, kernel_size=(5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 第三卷積塊:\n",
    "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(Conv2D(384, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 密集層\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='tanh'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 輸出層\n",
    "model.add(Dense(17, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03d88f4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T02:52:39.444658Z",
     "start_time": "2022-07-01T02:52:39.180212Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 54, 54, 96)        34944     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 26, 26, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 26, 26, 96)       384       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 22, 22, 256)       614656    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 10, 10, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 10, 10, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 6, 6, 384)         885120    \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 4, 4, 384)         1327488   \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 1, 1, 384)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 1, 1, 384)        1536      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 384)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4096)              1576960   \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 17)                69649     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,883,153\n",
      "Trainable params: 21,881,681\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cae2b6c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T09:56:42.594487Z",
     "start_time": "2022-07-01T02:53:43.429670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1224 samples, validate on 136 samples\n",
      "Epoch 1/100\n",
      "1224/1224 [==============================] - ETA: 0s - loss: 4.1786 - acc: 0.2271"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\keras\\engine\\training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1224/1224 [==============================] - 159s 130ms/sample - loss: 4.1786 - acc: 0.2271 - val_loss: 11.4456 - val_acc: 0.0735\n",
      "Epoch 2/100\n",
      "1224/1224 [==============================] - 157s 128ms/sample - loss: 3.2353 - acc: 0.2998 - val_loss: 4.9834 - val_acc: 0.0956\n",
      "Epoch 3/100\n",
      "1224/1224 [==============================] - 10235s 8s/sample - loss: 2.9192 - acc: 0.3154 - val_loss: 5.8172 - val_acc: 0.1103\n",
      "Epoch 4/100\n",
      "1224/1224 [==============================] - 181s 148ms/sample - loss: 2.3333 - acc: 0.3668 - val_loss: 5.2867 - val_acc: 0.1176\n",
      "Epoch 5/100\n",
      "1224/1224 [==============================] - 229s 187ms/sample - loss: 2.3146 - acc: 0.3971 - val_loss: 4.1221 - val_acc: 0.1471\n",
      "Epoch 6/100\n",
      "1224/1224 [==============================] - 195s 159ms/sample - loss: 2.4734 - acc: 0.4011 - val_loss: 3.3600 - val_acc: 0.2868\n",
      "Epoch 7/100\n",
      "1224/1224 [==============================] - 149s 121ms/sample - loss: 2.3117 - acc: 0.4118 - val_loss: 3.7488 - val_acc: 0.2574\n",
      "Epoch 8/100\n",
      "1224/1224 [==============================] - 150s 122ms/sample - loss: 2.0319 - acc: 0.4592 - val_loss: 2.7811 - val_acc: 0.2500\n",
      "Epoch 9/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 1.9401 - acc: 0.4583 - val_loss: 2.7441 - val_acc: 0.3897\n",
      "Epoch 10/100\n",
      "1224/1224 [==============================] - 168s 138ms/sample - loss: 1.6924 - acc: 0.5180 - val_loss: 4.2337 - val_acc: 0.2941\n",
      "Epoch 11/100\n",
      "1224/1224 [==============================] - 222s 182ms/sample - loss: 2.1132 - acc: 0.4526 - val_loss: 4.2421 - val_acc: 0.2941\n",
      "Epoch 12/100\n",
      "1224/1224 [==============================] - 190s 155ms/sample - loss: 2.2741 - acc: 0.4118 - val_loss: 3.0807 - val_acc: 0.2868\n",
      "Epoch 13/100\n",
      "1224/1224 [==============================] - 171s 139ms/sample - loss: 1.9593 - acc: 0.4673 - val_loss: 3.1684 - val_acc: 0.4044\n",
      "Epoch 14/100\n",
      "1224/1224 [==============================] - 157s 129ms/sample - loss: 2.0815 - acc: 0.4902 - val_loss: 2.9151 - val_acc: 0.3456\n",
      "Epoch 15/100\n",
      "1224/1224 [==============================] - 174s 142ms/sample - loss: 1.7402 - acc: 0.5400 - val_loss: 2.8463 - val_acc: 0.4191\n",
      "Epoch 16/100\n",
      "1224/1224 [==============================] - 165s 135ms/sample - loss: 1.4324 - acc: 0.5727 - val_loss: 2.8668 - val_acc: 0.4118\n",
      "Epoch 17/100\n",
      "1224/1224 [==============================] - 176s 144ms/sample - loss: 1.4773 - acc: 0.5801 - val_loss: 3.2506 - val_acc: 0.3824\n",
      "Epoch 18/100\n",
      "1224/1224 [==============================] - 157s 128ms/sample - loss: 1.5416 - acc: 0.5940 - val_loss: 3.3519 - val_acc: 0.3456\n",
      "Epoch 19/100\n",
      "1224/1224 [==============================] - 165s 135ms/sample - loss: 2.0885 - acc: 0.5147 - val_loss: 2.7470 - val_acc: 0.3750\n",
      "Epoch 20/100\n",
      "1224/1224 [==============================] - 153s 125ms/sample - loss: 1.6171 - acc: 0.5188 - val_loss: 4.1254 - val_acc: 0.3309\n",
      "Epoch 21/100\n",
      "1224/1224 [==============================] - 141s 115ms/sample - loss: 1.3785 - acc: 0.6062 - val_loss: 2.9083 - val_acc: 0.4338\n",
      "Epoch 22/100\n",
      "1224/1224 [==============================] - 139s 114ms/sample - loss: 1.2901 - acc: 0.6381 - val_loss: 2.5209 - val_acc: 0.4926\n",
      "Epoch 23/100\n",
      "1224/1224 [==============================] - 138s 112ms/sample - loss: 1.0633 - acc: 0.6920 - val_loss: 2.1236 - val_acc: 0.5735\n",
      "Epoch 24/100\n",
      "1224/1224 [==============================] - 141s 115ms/sample - loss: 1.3055 - acc: 0.6234 - val_loss: 2.5495 - val_acc: 0.4853\n",
      "Epoch 25/100\n",
      "1224/1224 [==============================] - 149s 122ms/sample - loss: 1.4631 - acc: 0.6275 - val_loss: 2.4744 - val_acc: 0.4853\n",
      "Epoch 26/100\n",
      "1224/1224 [==============================] - 149s 122ms/sample - loss: 1.4002 - acc: 0.6136 - val_loss: 2.6901 - val_acc: 0.4706\n",
      "Epoch 27/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 1.1654 - acc: 0.6855 - val_loss: 2.4121 - val_acc: 0.4779\n",
      "Epoch 28/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 1.0902 - acc: 0.6699 - val_loss: 2.6140 - val_acc: 0.4779\n",
      "Epoch 29/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 1.1159 - acc: 0.7141 - val_loss: 2.8621 - val_acc: 0.5221\n",
      "Epoch 30/100\n",
      "1224/1224 [==============================] - 149s 121ms/sample - loss: 0.8577 - acc: 0.7386 - val_loss: 2.3717 - val_acc: 0.4779\n",
      "Epoch 31/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.7339 - acc: 0.7900 - val_loss: 2.3711 - val_acc: 0.5368\n",
      "Epoch 32/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.7061 - acc: 0.7819 - val_loss: 1.8744 - val_acc: 0.6176\n",
      "Epoch 33/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.6291 - acc: 0.7982 - val_loss: 2.3201 - val_acc: 0.5441\n",
      "Epoch 34/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.7397 - acc: 0.7966 - val_loss: 3.1246 - val_acc: 0.5294\n",
      "Epoch 35/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.7203 - acc: 0.7892 - val_loss: 5.1300 - val_acc: 0.3162\n",
      "Epoch 36/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.7212 - acc: 0.7868 - val_loss: 2.2340 - val_acc: 0.5809\n",
      "Epoch 37/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.8566 - acc: 0.7696 - val_loss: 2.7425 - val_acc: 0.5662\n",
      "Epoch 38/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.6240 - acc: 0.8292 - val_loss: 2.7353 - val_acc: 0.5368\n",
      "Epoch 39/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.8795 - acc: 0.7500 - val_loss: 3.2069 - val_acc: 0.4853\n",
      "Epoch 40/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.7268 - acc: 0.7958 - val_loss: 4.9903 - val_acc: 0.3824\n",
      "Epoch 41/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 1.0485 - acc: 0.7255 - val_loss: 4.2372 - val_acc: 0.3750\n",
      "Epoch 42/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.8425 - acc: 0.7688 - val_loss: 3.8355 - val_acc: 0.4706\n",
      "Epoch 43/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.6239 - acc: 0.8268 - val_loss: 4.2931 - val_acc: 0.4853\n",
      "Epoch 44/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.6145 - acc: 0.8358 - val_loss: 3.7338 - val_acc: 0.4412\n",
      "Epoch 45/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.4980 - acc: 0.8578 - val_loss: 2.7874 - val_acc: 0.5221\n",
      "Epoch 46/100\n",
      "1224/1224 [==============================] - 147s 120ms/sample - loss: 0.5383 - acc: 0.8480 - val_loss: 3.4706 - val_acc: 0.5074\n",
      "Epoch 47/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.4896 - acc: 0.8529 - val_loss: 2.5421 - val_acc: 0.5735\n",
      "Epoch 48/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.7845 - acc: 0.8129 - val_loss: 4.0474 - val_acc: 0.4632\n",
      "Epoch 49/100\n",
      "1224/1224 [==============================] - 150s 122ms/sample - loss: 0.5046 - acc: 0.8627 - val_loss: 2.9913 - val_acc: 0.5735\n",
      "Epoch 50/100\n",
      "1224/1224 [==============================] - 149s 122ms/sample - loss: 0.5406 - acc: 0.8529 - val_loss: 2.8453 - val_acc: 0.5882\n",
      "Epoch 51/100\n",
      "1224/1224 [==============================] - 149s 122ms/sample - loss: 0.5491 - acc: 0.8619 - val_loss: 3.6461 - val_acc: 0.5294\n",
      "Epoch 52/100\n",
      "1224/1224 [==============================] - 154s 126ms/sample - loss: 0.3402 - acc: 0.9003 - val_loss: 4.2034 - val_acc: 0.5368\n",
      "Epoch 53/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.2328 - acc: 0.9404 - val_loss: 2.0707 - val_acc: 0.6544\n",
      "Epoch 54/100\n",
      "1224/1224 [==============================] - 149s 122ms/sample - loss: 0.3062 - acc: 0.9142 - val_loss: 2.9215 - val_acc: 0.5735\n",
      "Epoch 55/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.2123 - acc: 0.9379 - val_loss: 2.5782 - val_acc: 0.6397\n",
      "Epoch 56/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.5304 - acc: 0.8701 - val_loss: 3.8562 - val_acc: 0.5368\n",
      "Epoch 57/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.3917 - acc: 0.8913 - val_loss: 2.9763 - val_acc: 0.5882\n",
      "Epoch 58/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.3481 - acc: 0.9020 - val_loss: 3.1250 - val_acc: 0.6029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "1224/1224 [==============================] - 147s 120ms/sample - loss: 0.1951 - acc: 0.9355 - val_loss: 2.1726 - val_acc: 0.6544\n",
      "Epoch 60/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.0876 - acc: 0.9714 - val_loss: 2.3421 - val_acc: 0.6985\n",
      "Epoch 61/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.1699 - acc: 0.9444 - val_loss: 3.0266 - val_acc: 0.6397\n",
      "Epoch 62/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.3667 - acc: 0.9069 - val_loss: 3.2374 - val_acc: 0.5735\n",
      "Epoch 63/100\n",
      "1224/1224 [==============================] - 147s 120ms/sample - loss: 0.2658 - acc: 0.9167 - val_loss: 3.0870 - val_acc: 0.6103\n",
      "Epoch 64/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.3029 - acc: 0.9208 - val_loss: 3.5045 - val_acc: 0.5368\n",
      "Epoch 65/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.1404 - acc: 0.9526 - val_loss: 2.8003 - val_acc: 0.6618\n",
      "Epoch 66/100\n",
      "1224/1224 [==============================] - 149s 122ms/sample - loss: 0.1373 - acc: 0.9559 - val_loss: 2.8532 - val_acc: 0.6544\n",
      "Epoch 67/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.4092 - acc: 0.9044 - val_loss: 3.5424 - val_acc: 0.4926\n",
      "Epoch 68/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.2425 - acc: 0.9387 - val_loss: 4.1914 - val_acc: 0.5147\n",
      "Epoch 69/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.2179 - acc: 0.9346 - val_loss: 2.4667 - val_acc: 0.6691\n",
      "Epoch 70/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.2151 - acc: 0.9428 - val_loss: 2.9568 - val_acc: 0.5882\n",
      "Epoch 71/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.1287 - acc: 0.9567 - val_loss: 2.3957 - val_acc: 0.6912\n",
      "Epoch 72/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.1681 - acc: 0.9469 - val_loss: 2.6708 - val_acc: 0.6250\n",
      "Epoch 73/100\n",
      "1224/1224 [==============================] - 149s 122ms/sample - loss: 0.1594 - acc: 0.9567 - val_loss: 2.9255 - val_acc: 0.6397\n",
      "Epoch 74/100\n",
      "1224/1224 [==============================] - 154s 126ms/sample - loss: 0.1532 - acc: 0.9600 - val_loss: 3.2613 - val_acc: 0.6324\n",
      "Epoch 75/100\n",
      "1224/1224 [==============================] - 152s 124ms/sample - loss: 0.1185 - acc: 0.9681 - val_loss: 3.6082 - val_acc: 0.5882\n",
      "Epoch 76/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.2502 - acc: 0.9404 - val_loss: 4.9796 - val_acc: 0.4559\n",
      "Epoch 77/100\n",
      "1224/1224 [==============================] - 149s 122ms/sample - loss: 0.1496 - acc: 0.9567 - val_loss: 3.3159 - val_acc: 0.6103\n",
      "Epoch 78/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.0764 - acc: 0.9804 - val_loss: 3.5783 - val_acc: 0.5956\n",
      "Epoch 79/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.0834 - acc: 0.9739 - val_loss: 3.5075 - val_acc: 0.6176\n",
      "Epoch 80/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.1952 - acc: 0.9518 - val_loss: 3.4857 - val_acc: 0.6176\n",
      "Epoch 81/100\n",
      "1224/1224 [==============================] - 149s 122ms/sample - loss: 0.0861 - acc: 0.9755 - val_loss: 3.0272 - val_acc: 0.6397\n",
      "Epoch 82/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.0287 - acc: 0.9877 - val_loss: 3.6108 - val_acc: 0.6250\n",
      "Epoch 83/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.0238 - acc: 0.9910 - val_loss: 3.3369 - val_acc: 0.6618\n",
      "Epoch 84/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.0145 - acc: 0.9935 - val_loss: 2.7853 - val_acc: 0.6912\n",
      "Epoch 85/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.1940 - acc: 0.9673 - val_loss: 4.6088 - val_acc: 0.5074\n",
      "Epoch 86/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.2982 - acc: 0.9289 - val_loss: 4.8503 - val_acc: 0.4779\n",
      "Epoch 87/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.7055 - acc: 0.8676 - val_loss: 3.2699 - val_acc: 0.5662\n",
      "Epoch 88/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.3985 - acc: 0.8979 - val_loss: 3.2006 - val_acc: 0.6103\n",
      "Epoch 89/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.4243 - acc: 0.8873 - val_loss: 4.2718 - val_acc: 0.4853\n",
      "Epoch 90/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.3079 - acc: 0.9232 - val_loss: 3.9224 - val_acc: 0.5956\n",
      "Epoch 91/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.1942 - acc: 0.9428 - val_loss: 3.2438 - val_acc: 0.6029\n",
      "Epoch 92/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.3132 - acc: 0.9338 - val_loss: 3.9184 - val_acc: 0.5735\n",
      "Epoch 93/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.1607 - acc: 0.9469 - val_loss: 3.6192 - val_acc: 0.5735\n",
      "Epoch 94/100\n",
      "1224/1224 [==============================] - 149s 122ms/sample - loss: 1.1359 - acc: 0.8007 - val_loss: 5.5638 - val_acc: 0.4485\n",
      "Epoch 95/100\n",
      "1224/1224 [==============================] - 149s 121ms/sample - loss: 0.7184 - acc: 0.8358 - val_loss: 5.6557 - val_acc: 0.2868\n",
      "Epoch 96/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.5305 - acc: 0.8644 - val_loss: 6.0463 - val_acc: 0.3235\n",
      "Epoch 97/100\n",
      "1224/1224 [==============================] - 148s 121ms/sample - loss: 0.2925 - acc: 0.9216 - val_loss: 6.0554 - val_acc: 0.4118\n",
      "Epoch 98/100\n",
      "1224/1224 [==============================] - 149s 121ms/sample - loss: 0.7127 - acc: 0.8644 - val_loss: 8.3158 - val_acc: 0.3603\n",
      "Epoch 99/100\n",
      "1224/1224 [==============================] - 149s 122ms/sample - loss: 0.5304 - acc: 0.8864 - val_loss: 5.7610 - val_acc: 0.4779\n",
      "Epoch 100/100\n",
      "1224/1224 [==============================] - 155s 126ms/sample - loss: 0.2324 - acc: 0.9436 - val_loss: 4.3728 - val_acc: 0.5368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a6a3f6ce20>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#編譯模型\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#訓練模型\n",
    "model.fit(X, Y, batch_size=64, epochs=100, verbose=1, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e461335b",
   "metadata": {},
   "source": [
    "# VGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03a7cf13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T09:56:59.059823Z",
     "start_time": "2022-07-01T09:56:47.757743Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# 第一卷積塊:\n",
    "model.add(Conv2D(64, 3, activation='relu',\n",
    "           input_shape=(224, 224, 3)))\n",
    "model.add(Conv2D(64, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(BatchNormalization()) #批次正規化\n",
    "\n",
    "# 第二卷積塊:\n",
    "model.add(Conv2D(128,3, activation='relu'))\n",
    "model.add(Conv2D(128,3, activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 第三卷積塊:\n",
    "model.add(Conv2D(256, 3, activation='relu'))\n",
    "model.add(Conv2D(256, 3, activation='relu'))\n",
    "model.add(Conv2D(256, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 第四卷積塊:\n",
    "model.add(Conv2D(512, 3, activation='relu'))\n",
    "model.add(Conv2D(512, 3, activation='relu'))\n",
    "model.add(Conv2D(512, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 第五卷積塊:\n",
    "model.add(Conv2D(512, 3, activation='relu'))\n",
    "model.add(Conv2D(512, 3, activation='relu'))\n",
    "model.add(Conv2D(512, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 密集層\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# 輸出層\n",
    "model.add(Dense(17, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a752a68e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-01T09:56:59.500353Z",
     "start_time": "2022-07-01T09:56:59.153959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_9 (Conv2D)           (None, 222, 222, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 220, 220, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 110, 110, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 110, 110, 64)     256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 108, 108, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 106, 106, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 53, 53, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 53, 53, 128)      512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 51, 51, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 49, 49, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 47, 47, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 23, 23, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 23, 23, 256)      1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 21, 21, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 19, 19, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 17, 17, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 8, 8, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 8, 8, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 4, 4, 512)         2359808   \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 2, 2, 512)         2359808   \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 1, 1, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 1, 1, 512)        2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4096)              2101248   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 17)                69649     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,672,785\n",
      "Trainable params: 33,669,841\n",
      "Non-trainable params: 2,944\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1dbcd7",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-07-01T02:59:52.434Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1224 samples, validate on 136 samples\n",
      "Epoch 1/100\n",
      "1224/1224 [==============================] - 12025s 10s/sample - loss: 3.3206 - acc: 0.1397 - val_loss: 111.5480 - val_acc: 0.0441\n",
      "Epoch 2/100\n",
      " 320/1224 [======>.......................] - ETA: 2:24:10 - loss: 2.9960 - acc: 0.1437"
     ]
    }
   ],
   "source": [
    "#編譯模型\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#訓練模型\n",
    "model.fit(X, Y, batch_size=64, epochs=100, verbose=1, validation_split=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb1426c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-07-01T08:54:37.754Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense ,Dropout ,Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "vgg19 = VGG19(include_top=False,\n",
    "             weights= 'imagenet',\n",
    "             input_shape=(224,224,3),\n",
    "             pooling=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1703d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc570bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
